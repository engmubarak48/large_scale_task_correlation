{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92407331-e3d2-4472-86dc-088d2db57a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "from model import ResNet18\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from config import args as default_args\n",
    "from utils import DotDict, parse_arguments\n",
    "import torchvision.transforms as transforms\n",
    "from dataloader import CocoClassDatasetRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996931b1-879a-4d2e-bed6-426ea56c6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d391571-bb5e-4a86-b43a-5441e94bd674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.42s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.48s)\n",
      "creating index...\n",
      "index created!\n",
      "----> number of workers: 40\n"
     ]
    }
   ],
   "source": [
    "def change_to_3_channel(x):\n",
    "    if x.size()[0] == 1:\n",
    "        return x.repeat(3, 1, 1)\n",
    "    return x\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                                    # transforms.Resize(size=(224,224)),\n",
    "                                    # transforms.RandomCrop(224, padding=4),\n",
    "                                    # transforms.RandomHorizontalFlip(), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    change_to_3_channel,\n",
    "                                    transforms.Normalize(args.mean, args.std)\n",
    "                                ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    # transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    change_to_3_channel,\n",
    "    transforms.Normalize(args.mean, args.std),\n",
    "])\n",
    "\n",
    "train_dataset = CocoClassDatasetRandom(images_path = args.train_images_path, annotation_path = args.train_annotation_path, transform = train_transform)\n",
    "val_dataset = CocoClassDatasetRandom(images_path = args.val_images_path, annotation_path = args.val_annotation_path, transform = val_transform)\n",
    "\n",
    "print(f'----> number of workers: {args.num_workers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9fee0d2-0cb3-42b7-9045-774a154824b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ee8b33a-dfee-4063-9311-f76eb05f6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18() \n",
    "inp_features = net.linear.in_features\n",
    "net.linear = torch.nn.Linear(in_features=inp_features, out_features=args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06cbbef6-d1b8-4a75-bb6e-61d41639f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> verify if model is run on random data\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = next(iter(trainloader))\n",
    "\n",
    "print('-----> verify if model is run on random data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b195f56e-351d-4f4c-bbcb-e994ff75ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 224, 224]), torch.Size([4, 1, 40]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e13e3adf-fec0-45b7-b320-34535fb704de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([4, 40]), batch labels shape: torch.Size([4, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "outputs = net(batch_x)\n",
    "\n",
    "print(f'Outputs shape: {outputs.shape}, batch labels shape: {batch_y.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aad2976-abfc-4e1f-8c7e-d58b0f328645",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = args.base_learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76a81ffe-1465-4e60-894e-3d7d69eb13a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random loss: 0.7418841123580933\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial random loss: {criterion(outputs, batch_y.squeeze().float())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f811ca0-54d3-4146-b19f-9e94df704885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75771b05-a151-489a-a91e-c8969643a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 0., 0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.round(torch.sigmoid(outputs))\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95432996-f81c-4e26-a2e7-32653f927434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True, False, False,  True, False,  True,  True, False,\n",
       "         False,  True, False, False,  True, False,  True,  True,  True, False,\n",
       "         False, False,  True, False, False, False,  True,  True, False,  True,\n",
       "         False, False, False,  True,  True, False,  True,  True,  True,  True],\n",
       "        [False,  True, False, False, False, False, False,  True,  True, False,\n",
       "          True,  True, False, False,  True, False,  True,  True,  True,  True,\n",
       "         False, False,  True, False, False, False,  True,  True, False,  True,\n",
       "         False,  True, False,  True,  True, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False,  True, False,  True, False, False,  True,\n",
       "         False, False,  True, False, False, False,  True, False, False,  True,\n",
       "         False,  True, False, False,  True, False,  True,  True,  True,  True],\n",
       "        [False, False,  True, False, False,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
       "         False, False,  True, False, False, False,  True,  True, False,  True,\n",
       "         False,  True, False,  True,  True, False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.eq(batch_y.squeeze().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48a34de0-0ee2-4304-b3cc-4f89ec6de41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(80)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = predicted.eq(batch_y.squeeze().float()).cpu().sum()\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17d8219b-6819-4eef-8e83-3586dfd2da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random acc: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "random_acc = correct/(batch_size * args.num_classes) * 100\n",
    "print(f'Initial random acc: {random_acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "899b6015-1f5d-4301-9525-a7ecc123bd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size * args.num_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
